Namespace(arch='resnet18', backend=<BackendType.Academic: 'Academic'>, batch_size=512, config_file='./configs/resnet18_w2a2_lsq.yaml', deploy=False, dist_backend='nccl', dist_url='env://', distributed=True, epochs=100, evaluate=False, gpu=0, lr=5e-05, lr_scheduler='Cosine', model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, model_path='./pretrained/resnet18_imagenet.pth.tar', momentum=0.9, multiprocessing_distributed=True, not_quant=False, optim='adam', out_dir='/workspace/service/outputs/00a2b1a8-316c-47d1-8db2-eb9de284ee60/resnet18_w2a2_20230729-065947', output_dir='/workspace/service/outputs/00a2b1a8-316c-47d1-8db2-eb9de284ee60', pretrained=False, print_freq=100, quant=True, quantization={'enabled': True, 'type': 'Academic', 'qparams': {'w_observer': 'LSQObserver', 'w_fakequantize': 'LearnableFakeQuantize', 'w_qscheme': {'bit': 2, 'symmetry': True, 'per_channel': False, 'pot_scale': False}, 'a_observer': 'LSQObserver', 'a_fakequantize': 'LearnableFakeQuantize', 'a_qscheme': {'bit': 2, 'symmetry': False, 'per_channel': False, 'pot_scale': False}}}, rank=0, resume=None, seed=None, start_epoch=0, train_data='/workspace/dataset/imagenet', val_data='/workspace/dataset/imagenet', weight_decay=2.5e-05, workers=4, world_size=4)
Use GPU: 0 for training
Added key: store_based_barrier_key:1 to store for rank: 0
Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
=> creating model 'resnet18'
load pretrained checkpoint from: ./pretrained/resnet18_imagenet.pth.tar
